{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14198,"status":"ok","timestamp":1605249793348,"user":{"displayName":"‍안진우[학생](공과대학 산업경영공학과)","photoUrl":"","userId":"03552836888386422888"},"user_tz":-540},"id":"jxhj4nbSV6K2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n","Requirement already satisfied: pillow\u003e=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 35.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 38.3MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version \u003c \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 37.8MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses-\u003etransformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses-\u003etransformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses-\u003etransformers) (0.17.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf-\u003etransformers) (50.3.2)\n","Requirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging-\u003etransformers) (2.4.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests-\u003etransformers) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-\u003etransformers) (2.10)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=13c3b17991cffcd6fa24695e9bbfd10b59a5124f679ad8b574c7f0a0b919d41b\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n","Collecting wikipedia\n","  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.6.3)\n","Requirement already satisfied: requests\u003c3.0.0,\u003e=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests\u003c3.0.0,\u003e=2.0.0-\u003ewikipedia) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests\u003c3.0.0,\u003e=2.0.0-\u003ewikipedia) (2020.11.8)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.6/dist-packages (from requests\u003c3.0.0,\u003e=2.0.0-\u003ewikipedia) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests\u003c3.0.0,\u003e=2.0.0-\u003ewikipedia) (3.0.4)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp36-none-any.whl size=11686 sha256=eb226dd4bb2a6b1654159de7dff46b7b10ab2d3b17c180c3b36e3ae7d92d7269\n","  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n","Successfully built wikipedia\n","Installing collected packages: wikipedia\n","Successfully installed wikipedia-1.4.0\n"]}],"source":["#필요한 torch 버전 다운로드\n","#위키피디아 예제를 원래 링크에서는 사용하였음. 근데 여기 파일에선 안했음 \n","#https://qa.fastforwardlabs.com/pytorch/hugging%20face/wikipedia/bert/transformers/2020/05/19/Getting_Started_with_QA.html\n","!pip install torch  torchvision -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install transformers\n","!pip install wikipedia"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9082,"status":"ok","timestamp":1605249812853,"user":{"displayName":"‍안진우[학생](공과대학 산업경영공학과)","photoUrl":"","userId":"03552836888386422888"},"user_tz":-540},"id":"NENUDyNNWB7U"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: DATA_DIR=./data/squad\n","--2020-11-27 04:43:32--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n","Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n","Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 42123633 (40M) [application/json]\n","Saving to: ‘./data/squad/train-v2.0.json’\n","\n","train-v2.0.json     100%[===================\u003e]  40.17M   112MB/s    in 0.4s    \n","\n","2020-11-27 04:43:33 (112 MB/s) - ‘./data/squad/train-v2.0.json’ saved [42123633/42123633]\n","\n","--2020-11-27 04:43:33--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n","Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n","Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4370528 (4.2M) [application/json]\n","Saving to: ‘./data/squad/dev-v2.0.json’\n","\n","dev-v2.0.json       100%[===================\u003e]   4.17M  --.-KB/s    in 0.08s   \n","\n","2020-11-27 04:43:33 (50.4 MB/s) - ‘./data/squad/dev-v2.0.json’ saved [4370528/4370528]\n","\n"]}],"source":["# set path with magic\n","%env DATA_DIR=./data/squad \n","\n","# download the data\n","#두번째 다운로드함(이게 최신 squad 2)\n","def download_squad(version=1):\n","    if version == 1:\n","        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n","        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n","    else:\n","        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n","        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n","            \n","download_squad(version=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2155,"status":"ok","timestamp":1605249819650,"user":{"displayName":"‍안진우[학생](공과대학 산업경영공학과)","photoUrl":"","userId":"03552836888386422888"},"user_tz":-540},"id":"hGfcWdrYWEcB"},"outputs":[{"name":"stdout","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 34740  100 34740    0     0   155k      0 --:--:-- --:--:-- --:--:--  155k\n"]}],"source":["# download the run_squad.py training script\n","# auto training 모델 파일 다운로드\n","!curl -L -O https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/run_squad.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rDko0so8WJE6"},"outputs":[],"source":["# fine-tuning your own model for QA using HF's `run_squad.py`\n","# turn flags on and off according to the model you're training\n","# squad.py에 적용할 parameter들을 설정 =\u003e 이건 우리한테 맞게 하면 될듯\n","cmd = [\n","    'python', \n","#    '-m torch.distributed.launch --nproc_per_node 2', # use this to perform distributed training over multiple GPUs\n","    'run_squad.py', \n","    \n","    '--model_type', 'bert',                            # model type (one of the list under \"Pick a Model\" above)\n","    \n","    '--model_name_or_path', 'bert-base-uncased',       # specific model name of the given model type (shown, a list is here: https://huggingface.co/transformers/pretrained_models.html) \n","                                                       # on first execution this initiates a download of pre-trained model weights;\n","                                                       # can also be a local path to a directory with model weights\n","    \n","    '--output_dir', './models/bert/bbu_squad2',        # directory for model checkpoints and predictions\n","    \n","#    '--overwrite_output_dir',                         # use when adding output to a directory that is non-empty --\n","                                                       # for instance, when training crashes midway through and you need to restart it\n","    \n","    '--do_train',                                      # execute the training method \n","    \n","    '--train_file', '$DATA_DIR/train-v2.0.json',       # provide the training data\n","    \n","    '--version_2_with_negative',                       # ** MUST use this flag if training on SQuAD 2.0! DO NOT use if training on SQuAD 1.1\n","    \n","    '--do_lower_case',                                 # ** set this flag if using an uncased model; don't use for Cased Models\n","    \n","    '--do_eval',                                       # execute the evaluation method on the dev set -- note: \n","                                                       # if coupled with --do_train, evaluation runs after fine-tuning \n","    \n","    '--predict_file', '$DATA_DIR/dev-v2.0.json',       # provide evaluation data (dev set)\n","    \n","    '--eval_all_checkpoints',                          # evaluate the model on the dev set at each checkpoint\n","    \n","    '--per_gpu_eval_batch_size', '12',                 # evaluation batch size for each gpu\n","    \n","    '--per_gpu_train_batch_size', '12',                # training batch size for each gpu\n","    \n","    '--save_steps', '5000',                            # how often checkpoints (complete model snapshot) are saved \n","    \n","    '--threads', '8',                                  # num of CPU threads to use for converting SQuAD examples to model features\n","    \n","    # --- Model and Feature Hyperparameters --- \n","    '--num_train_epochs', '3',                         # number of training epochs - usually 2-3 for SQuAD \n","    \n","    '--learning_rate', '3e-5',                         # learning rate for the default optimizer (Adam in this case)\n","    \n","    '--max_seq_length', '384',                         # maximum length allowed for the full input sequence \n","    \n","    '--doc_stride', '128'                              # used for long documents that must be chunked into multiple features -- \n","                                                       # this \"sliding window\" controls the amount of stride between chunks\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1619557,"status":"ok","timestamp":1605251505025,"user":{"displayName":"‍안진우[학생](공과대학 산업경영공학과)","photoUrl":"","userId":"03552836888386422888"},"user_tz":-540},"id":"wAi4QkBJWVJr"},"outputs":[{"name":"stdout","output_type":"stream","text":["2020-11-27 04:43:37.264933: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","11/27/2020 04:43:40 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n","11/27/2020 04:43:40 - INFO - filelock -   Lock 140271926538368 acquired on /root/.cache/torch/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170.lock\n","[INFO|file_utils.py:1162] 2020-11-27 04:43:40,351 \u003e\u003e https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp3xpy6z9r\n","Downloading: 100% 433/433 [00:00\u003c00:00, 348kB/s]\n","[INFO|file_utils.py:1166] 2020-11-27 04:43:40,619 \u003e\u003e storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/torch/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n","[INFO|file_utils.py:1169] 2020-11-27 04:43:40,619 \u003e\u003e creating metadata file for /root/.cache/torch/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n","11/27/2020 04:43:40 - INFO - filelock -   Lock 140271926538368 released on /root/.cache/torch/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170.lock\n","[INFO|configuration_utils.py:413] 2020-11-27 04:43:40,620 \u003e\u003e loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/torch/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n","[INFO|configuration_utils.py:449] 2020-11-27 04:43:40,621 \u003e\u003e Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|configuration_utils.py:413] 2020-11-27 04:43:40,893 \u003e\u003e loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/torch/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n","[INFO|configuration_utils.py:449] 2020-11-27 04:43:40,894 \u003e\u003e Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","11/27/2020 04:43:41 - INFO - filelock -   Lock 140270787758064 acquired on /root/.cache/torch/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n","[INFO|file_utils.py:1162] 2020-11-27 04:43:41,169 \u003e\u003e https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpx6f5taha\n","Downloading: 100% 232k/232k [00:00\u003c00:00, 908kB/s]\n","[INFO|file_utils.py:1166] 2020-11-27 04:43:41,701 \u003e\u003e storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/torch/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|file_utils.py:1169] 2020-11-27 04:43:41,701 \u003e\u003e creating metadata file for /root/.cache/torch/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","11/27/2020 04:43:41 - INFO - filelock -   Lock 140270787758064 released on /root/.cache/torch/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n","[INFO|tokenization_utils_base.py:1650] 2020-11-27 04:43:41,702 \u003e\u003e loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/torch/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","11/27/2020 04:43:42 - INFO - filelock -   Lock 140270787279504 acquired on /root/.cache/torch/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n","[INFO|file_utils.py:1162] 2020-11-27 04:43:42,011 \u003e\u003e https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpumfvuscn\n","Downloading: 100% 440M/440M [00:05\u003c00:00, 78.7MB/s]\n","[INFO|file_utils.py:1166] 2020-11-27 04:43:47,807 \u003e\u003e storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/torch/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[INFO|file_utils.py:1169] 2020-11-27 04:43:47,807 \u003e\u003e creating metadata file for /root/.cache/torch/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","11/27/2020 04:43:47 - INFO - filelock -   Lock 140270787279504 released on /root/.cache/torch/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n","[INFO|modeling_utils.py:940] 2020-11-27 04:43:47,808 \u003e\u003e loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[WARNING|modeling_utils.py:1048] 2020-11-27 04:43:52,021 \u003e\u003e Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:1059] 2020-11-27 04:43:52,021 \u003e\u003e Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","11/27/2020 04:43:52 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='data/squad', device=device(type='cpu'), do_eval=True, do_lower_case=True, do_train=True, doc_stride=128, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, lang_id=0, learning_rate=3e-05, local_rank=-1, logging_steps=500, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_best_size=20, n_gpu=0, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=2.0, output_dir='models/bert/', overwrite_cache=True, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=2, predict_file='dev-v2.0.json', save_steps=5000, seed=42, server_ip='', server_port='', threads=10, tokenizer_name='', train_file='train-v2.0.json', verbose_logging=False, version_2_with_negative=True, warmup_steps=0, weight_decay=0.0)\n","11/27/2020 04:43:52 - INFO - __main__ -   Creating features from dataset file at data/squad\n","100% 442/442 [00:48\u003c00:00,  9.20it/s]\n","convert squad examples to features:   0% 0/130319 [00:00\u003c?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","convert squad examples to features: 100% 130319/130319 [24:22\u003c00:00, 89.10it/s]\n","add example index and unique id: 100% 130319/130319 [00:00\u003c00:00, 823177.85it/s]\n","11/27/2020 05:09:08 - INFO - __main__ -   Saving features into cached file data/squad/cached_train_bert-base-uncased_384\n","tcmalloc: large alloc 1179656192 bytes == 0x21d220000 @  0x7f93f44202a4 0x591e47 0x4dd737 0x4dd7cf 0x4e1dad 0x4e22bf 0x4e297c 0x4e0df8 0x4e255b 0x4e233b 0x4e29d0 0x4e33c6 0x5eb562 0x50a1cc 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4\n","tcmalloc: large alloc 1769480192 bytes == 0x263722000 @  0x7f93f44202a4 0x591e47 0x4dd737 0x4e1f67 0x4e2313 0x4e29d0 0x4e0df8 0x4e255b 0x4e22eb 0x4e29d0 0x4e33c6 0x5eb562 0x50a1cc 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4\n","^C\n"]}],"source":["!python run_squad.py  \\\n","    --model_type bert   \\\n","    --model_name_or_path bert-base-uncased  \\\n","    --output_dir models/bert/ \\\n","    --data_dir data/squad   \\\n","    --overwrite_output_dir \\\n","    --overwrite_cache \\\n","    --do_train  \\\n","    --train_file train-v2.0.json   \\\n","    --version_2_with_negative \\\n","    --do_lower_case  \\\n","    --do_eval  \\\n","    --predict_file dev-v2.0.json   \\\n","    --per_gpu_train_batch_size 2   \\\n","    --learning_rate 3e-5   \\\n","    --num_train_epochs 2.0   \\\n","    --max_seq_length 384   \\\n","    --doc_stride 128   \\\n","    --threads 10   \\\n","    --save_steps 5000 "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":66},"executionInfo":{"elapsed":54547,"status":"ok","timestamp":1605251862672,"user":{"displayName":"‍안진우[학생](공과대학 산업경영공학과)","photoUrl":"","userId":"03552836888386422888"},"user_tz":-540},"id":"sAfMUbBBX6IN"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1027d655b8f45608336e86a769a0de9","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=508.0, style=ProgressStyle(description_…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c84f722e37e14c2c9afe4c217f74e491","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fe6be3d18d6463b9e6de7687427ca6c","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1054f1b0edc4e5e964e2a2d465a927c","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=152.0, style=ProgressStyle(description_…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ea459f4336644f089bfb258fdc7f567","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433294681.0, style=ProgressStyle(descri…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["#이건 이미 있는 로드되어있는 모델들을 가져오는 것. Multilingual을 가져오던가 아니면\n","#위에서 훈련시킨 파일에 밑에 질문같은것들을 덧붙혀야될듯?\n","import torch\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","\n","# executing these commands for the first time initiates a download of the \n","# model weights to ~/.cache/torch/transformers/\n","tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\") \n","model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/bert-base-cased-squad2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1348,"status":"ok","timestamp":1605251916506,"user":{"displayName":"‍안진우[학생](공과대학 산업경영공학과)","photoUrl":"","userId":"03552836888386422888"},"user_tz":-540},"id":"LuYiTPB4X7kh"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'the Argead dynasty'"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#위의 가져온 모델에다가 적용한거임. 근데 위위에서 훈련시킨 squad.py에서 이 질문들 어케 따로 적용하지;; 아마 안에서 돌려야되는듯\n","question = \"Who ruled Macedonia\"\n","\n","context = \"\"\"Macedonia was an ancient kingdom on the periphery of Archaic and Classical Greece, \n","and later the dominant state of Hellenistic Greece. The kingdom was founded and initially ruled \n","by the Argead dynasty, followed by the Antipatrid and Antigonid dynasties. Home to the ancient \n","Macedonians, it originated on the northeastern part of the Greek peninsula. Before the 4th \n","century BC, it was a small kingdom outside of the area dominated by the city-states of Athens, \n","Sparta and Thebes, and briefly subordinate to Achaemenid Persia.\"\"\"\n","\n","\n","# 1. TOKENIZE THE INPUT\n","# note: if you don't include return_tensors='pt' you'll get a list of lists which is easier for \n","# exploration but you cannot feed that into a model. \n","inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\") \n","\n","# 2. OBTAIN MODEL SCORES\n","# the AutoModelForQuestionAnswering class includes a span predictor on top of the model. \n","# the model returns answer start and end scores for each word in the text\n","answer_start_scores, answer_end_scores = model(**inputs)\n","answer_start = torch.argmax(answer_start_scores)  # get the most likely beginning of answer with the argmax of the score\n","answer_end = torch.argmax(answer_end_scores) + 1  # get the most likely end of answer with the argmax of the score\n","\n","# 3. GET THE ANSWER SPAN\n","# once we have the most likely start and end tokens, we grab all the tokens between them\n","# and convert tokens back to words!\n","tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZCFw0Xm5mwJ4"},"outputs":[],"source":["import transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1068,"status":"ok","timestamp":1605254225440,"user":{"displayName":"‍안진우[학생](공과대학 산업경영공학과)","photoUrl":"","userId":"03552836888386422888"},"user_tz":-540},"id":"xoEVdCiRm4Mm"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'3.5.1'"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["transformers.__version__"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOMwrCzDRIyM0kG7gV1TWrz","collapsed_sections":[],"name":"pytorch_bertqa.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"54a2c9e3713240529b1a56e388b0559c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7da8912631c4432fbaa8ecc88fda931e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cbfe4dd94594b4e9905a5dd520523c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c53033c35fb44b0d8305a1a4bb487cf5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5d4c51c7bf342bfa7060d8c1dad146b","IPY_MODEL_ff0198a62cf3409aa67e3871cf374bdd"],"layout":"IPY_MODEL_54a2c9e3713240529b1a56e388b0559c"}},"d142348534b14345a60de89802bfbd66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"d5d4c51c7bf342bfa7060d8c1dad146b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_ef3d69b03bf649cfb2856abba0fd908a","max":433294681,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d142348534b14345a60de89802bfbd66","value":433294681}},"ef3d69b03bf649cfb2856abba0fd908a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff0198a62cf3409aa67e3871cf374bdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cbfe4dd94594b4e9905a5dd520523c2","placeholder":"​","style":"IPY_MODEL_7da8912631c4432fbaa8ecc88fda931e","value":" 433M/433M [19:48\u0026lt;00:00, 364kB/s]"}}}}},"nbformat":4,"nbformat_minor":0}